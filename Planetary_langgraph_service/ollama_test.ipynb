{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage # Import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import Literal, List, Dict, Any, Optional\n",
    "import operator\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime # Import datetime\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List, Sequence, Tuple, TypedDict, Union\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from langchain_core.messages.function import FunctionMessage\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import operator\n",
    "import functools\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "import uuid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f85ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> Learn how to become a full stack web developer in 2025 with this comprehensive guide. It covers front-end, back-end, database, and version control systems, as well as popular technologies like MERN, MEAN, HTML, CSS, JavaScript, and more. This Java Full Stack Developer roadmap has been meticulously crafted through extensive research into emerging technologies and industry trends. It anticipates the future demands of the tech landscape, ensuring that you're equipped with the skills and knowledge needed to stay ahead of the curve and thrive in the rapidly evolving field of ... Here's your step-by-step roadmap to becoming a confident, job-ready full stack developer. What Does \"Full Stack\" Mean? The \"stack\" refers to the collection of technologies used to build a complete web application. It typically includes: Frontend (what users see): The layout, buttons, text, visuals, and animations â€” everything on screen. Everything About Full Stack Developer Roadmap in 2025. The full stack developer roadmap explains that the journey to becoming a full stack developer is exciting and filled with learning opportunities.. Here's the full stack developer roadmap tailored for aspiring developers in 2025, focusing on a structured path to mastering full stack development. This comprehensive full stack developer roadmap will lead you step by step, equipping you with the essential skills for a successful career in full-stack web development. Also Read: What is Unit Testing in Python? Front-end Technology Roadmap for Full-Stack Web Development. This roadmap provides a comprehensive overview of the front-end ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "res = search.invoke(\"Full stack roadmap\")\n",
    "print(type(res), res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ddbc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def webSearchTool(query:str):\n",
    "    \"\"\"\n",
    "    Perform a web search using DuckDuckGo.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "\n",
    "    Returns:\n",
    "        str: The search results returned by DuckDuckGo.\n",
    "    \"\"\"\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    res = search.invoke(query)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fff4cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Define the prompt for tool calling ---\n",
    "tool_calling_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a helpful AI assistant, who is designed to create planners. The user give anything for which you need to make a detailed plan for the user. For example, the user can ask \"I want to learn DSA to crack interviews.\" or \"I want to visit Ooty, make a itenary\".\n",
    "\n",
    "    You have access to the following tools:\n",
    "    {tools}\n",
    "\n",
    "    When the user asks a question that requires a tool, respond by setting the \"tool_calling_required\" flag as true.\n",
    "    For example:\n",
    "    <tool_code>\n",
    "    {{\n",
    "        \"tool_calling_required\" : true,\n",
    "        \"tool_name\": \"webSearchTool\",\n",
    "        \"args\": {{\n",
    "            \"query\": \"What is the roadmap for learning Full Stack development\"\n",
    "        }}\n",
    "    }}\n",
    "    </tool_code>\n",
    "    Do NOT make up tool calls if you don't have enough information.\n",
    "    If you have just received tool outputs, synthesize a natural language response for the user based on the chat history and the tool outputs.\n",
    "    NOTE: YOUR FINAL ANSWER SHOULD BE A JSON OBJECT WHICH I CAN DIRECTLY PARSE WITH json.loads PYTHON METHOD. YOUR FINAL ANSWER WILL BE A DIRECT INPUT TO A FRONTEND APPLICAION WHICH WILL BE MAPPED TO UI ELEMENTS. IF YOU HAVE THE FINAL ANSWER, \"tool_calling_required\" FIELD SHOULD BE false.\n",
    "    The Structure of the final ans:\n",
    "    {{\n",
    "        \"tool_calling_required\" : false,\n",
    "        \"final_answer\": <List of Tasks Object>\n",
    "    }}\n",
    "    JSON Structure of Task Object:\n",
    "    {{\n",
    "        \"title\" : <Title of Task>\n",
    "        \"sub_tasks\" : <List of Actions to complete this Task>\n",
    "    }} \n",
    "     \n",
    "     Example of a final answer:\n",
    "     {{\n",
    "        \"tool_calling_required\" : false,\n",
    "        \"final_answer\": [\n",
    "            {{\n",
    "                \"title\": \"Study Time complexity\",\n",
    "                \"sub_tasks\": [\n",
    "                    \"Study big O notation\",\n",
    "                    \"Study about different types of timeplexity like O(N), O(logN) etc\"\n",
    "                ] \n",
    "            }},\n",
    "            {{\n",
    "                \"title\": \"Arrays\",\n",
    "                \"sub_tasks\": [\n",
    "                    \"Searching in array\",\n",
    "                    \"Sorting an array\",\n",
    "                    \"Prefix sum\",\n",
    "                ] \n",
    "            }},...\n",
    "        ]\n",
    "     }}\n",
    "    \"\"\"),\n",
    "    (\"placeholder\", \"{chat_history}\"), # Placeholder for full chat history\n",
    "    (\"user\", \"{input}\") # Only original user input, subsequent turns are in chat_history\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc2b056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the tool description for the prompt\n",
    "tools_description = \"\"\"\n",
    "- Name: webSearchTool\n",
    "  Description: Perform a web search using DuckDuckGo.\n",
    "  Parameters:\n",
    "    - query: string (REQUIRED) - The query to search on the web.\n",
    "\"\"\"\n",
    "\n",
    "# --- 1. Initialize Ollama chat model ---\n",
    "llm = ChatOllama(model=\"llama3.1\", base_url=\"http://localhost:11434\", temperature=0.1)\n",
    "\n",
    "# --- LangGraph Agent Setup ---\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str # Original user query\n",
    "    chat_history: Annotated[List[Any], operator.add] # List of messages (Human, AI, Tool)\n",
    "    tool_calls: List[Dict[str, Any]] # Tool calls detected by LLM\n",
    "    tool_outputs: List[Any] # Outputs from tool execution\n",
    "    final_answer: Optional[str] # Final natural language answer\n",
    "\n",
    "def call_llm(state: AgentState):\n",
    "    current_input_messages = []\n",
    "    # If this is the start of the conversation, use the 'input'\n",
    "    if not state[\"chat_history\"]:\n",
    "        current_input_messages.append(HumanMessage(content=state[\"input\"]))\n",
    "    else:\n",
    "        # If it's a follow-up after a tool call, the relevant info is in chat_history\n",
    "        # The prompt handles how to interpret the history.\n",
    "        pass # chat_history is already passed by placeholder\n",
    "\n",
    "    # Construct messages for the LLM, including history\n",
    "    messages_for_llm = state[\"chat_history\"] + current_input_messages\n",
    "\n",
    "    prompt_formatted = tool_calling_prompt.format(\n",
    "        tools=tools_description,\n",
    "        input=state[\"input\"], # The original input for initial prompt context\n",
    "        chat_history=messages_for_llm # Pass the full list of messages\n",
    "    )\n",
    "    # Using `invoke` with `input` and `chat_history` args of prompt directly\n",
    "    # This might need adjustment depending on how `ChatOllama` handles prompt templates\n",
    "    # For now, let's use the formatted string.\n",
    "    response = llm.invoke(prompt_formatted)\n",
    "    content = response.content\n",
    "    print(\"Response: \", content[content.find('{'): content.rfind('}') + 1])\n",
    "    response_json = json.loads(content[content.find('{'): content.rfind('}') + 1])\n",
    "    print(\"Success\")\n",
    "    tool_calls = []\n",
    "    final_answer = None # Start as None\n",
    "\n",
    "    tool_calling_required = response_json['tool_calling_required']\n",
    "    print(\"Tool Calling Required: \", tool_calling_required)\n",
    "    \n",
    "    # Simple regex to extract the tool_code block\n",
    "\n",
    "    if tool_calling_required:\n",
    "        try:\n",
    "            tool_calls.append(response_json)\n",
    "            # Remove the tool_code block from the content\n",
    "            content_without_tool_code = re.sub(r\"<tool_code>.*?</tool_code>\", \"\", content, flags=re.DOTALL).strip()\n",
    "            # If there's still meaningful content, maybe it's a preamble\n",
    "            if content_without_tool_code:\n",
    "                print(f\"LLM also said: {content_without_tool_code}\") # For debugging\n",
    "                # Decide if this content should be part of chat history or discarded\n",
    "                # For now, we prioritize tool_calls\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Warning: Could not parse tool_code JSON. Treating as regular text.\")\n",
    "            final_answer = content # Treat as final answer if tool call parsing fails\n",
    "    else:\n",
    "        final_answer = response_json['final_answer'] # No tool call detected, assume it's a direct answer\n",
    "\n",
    "    # Append AI's full response (including potential tool_code) to chat history\n",
    "    new_chat_history_entry = [AIMessage(content=content)]\n",
    "\n",
    "    return {\n",
    "        \"chat_history\": new_chat_history_entry, # Only add the *latest* LLM message\n",
    "        \"tool_calls\": tool_calls,\n",
    "        \"final_answer\": final_answer\n",
    "    }\n",
    "\n",
    "def call_tool(state: AgentState):\n",
    "    tool_outputs = []\n",
    "    # Loop through tool calls (though often there's just one per turn)\n",
    "    for tool_call in state[\"tool_calls\"]:\n",
    "        tool_name = tool_call.get(\"tool_name\")\n",
    "        args = tool_call.get(\"args\", {})\n",
    "\n",
    "        if tool_name == \"webSearchTool\":\n",
    "            output = webSearchTool(**args)\n",
    "            tool_outputs.append(output)\n",
    "            tool_message_content = {\"tool_calls\": [tool_call], \"output\": output}\n",
    "        else:\n",
    "            error_msg = f\"Error: Tool '{tool_name}' not found.\"\n",
    "            tool_outputs.append(error_msg)\n",
    "            tool_message_content = {\"tool_calls\": [tool_call], \"error\": error_msg}\n",
    "\n",
    "    # Crucial: Return a ToolMessage with the output to be added to chat history\n",
    "    # This is how the LLM \"sees\" the result of its tool call.\n",
    "    return {\n",
    "        \"tool_outputs\": tool_outputs,\n",
    "        \"chat_history\": [ToolMessage(tool_message_content, tool_call_id=str(uuid.uuid4()))] # Unique ID\n",
    "    }\n",
    "\n",
    "# def jsonParserAgent(state: AgentState):\n",
    "\n",
    "def decide_next_step(state: AgentState):\n",
    "    if state[\"tool_calls\"]:\n",
    "        print(\"Decision: Calling Tool\")\n",
    "        return \"call_tool\"\n",
    "    elif state[\"final_answer\"]:\n",
    "        print(\"Decision: Ending Chat (Final Answer)\")\n",
    "        return \"end_chat\"\n",
    "    else:\n",
    "        # Fallback for unexpected scenarios, or if LLM didn't give a final answer\n",
    "        # but also didn't call a tool. Could mean it needs more turns.\n",
    "        # For a roadmap, this might be a loop for refinement.\n",
    "        print(\"Decision: No tool call, no final answer. Trying LLM again or ending.\")\n",
    "        # If you want to loop back to LLM to try to generate a final answer\n",
    "        # based on history, return \"call_llm\"\n",
    "        # If you want to stop if nothing useful happens, return END\n",
    "        return END # Changed to END for safety in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bee994c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LangGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"call_llm\", call_llm)\n",
    "workflow.add_node(\"call_tool\", call_tool)\n",
    "\n",
    "workflow.set_entry_point(\"call_llm\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_llm\",\n",
    "    decide_next_step, # Function to decide next edge\n",
    "    {\n",
    "        \"call_tool\": \"call_tool\",\n",
    "        \"end_chat\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After tool execution, always go back to LLM for synthesis\n",
    "workflow.add_edge(\"call_tool\", \"call_llm\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eca77a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test 1: Direct Answer ---\n",
      "Response:  {\n",
      "  \"tool_calling_required\" : true,\n",
      "  \"tool_name\": \"webSearchTool\",\n",
      "  \"args\": {\n",
      "    \"query\": \"Full Stack Development Roadmap\"\n",
      "  }\n",
      "}\n",
      "Success\n",
      "Tool Calling Required:  True\n",
      "LLM also said: {\n",
      "  \"tool_calling_required\" : true,\n",
      "  \"tool_name\": \"webSearchTool\",\n",
      "  \"args\": {\n",
      "    \"query\": \"Full Stack Development Roadmap\"\n",
      "  }\n",
      "}\n",
      "Decision: Calling Tool\n",
      "Response:  {\n",
      "  \"tool_calling_required\" : false,\n",
      "  \"final_answer\": [\n",
      "    {\n",
      "      \"title\": \"Understand Full Stack Development\",\n",
      "      \"sub_tasks\": [\n",
      "        \"Read the definition of Full Stack Development from the guide provided by the tool output.\",\n",
      "        \"Understand the components of a full stack, including frontend and backend.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Frontend Skills\",\n",
      "      \"sub_tasks\": [\n",
      "        \"Learn HTML, CSS, and JavaScript as per the guide's recommendations.\",\n",
      "        \"Explore popular front-end frameworks like React or Angular.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Backend Skills\",\n",
      "      \"sub_tasks\": [\n",
      "        \"Study backend languages such as Node.js, Python, or Ruby as mentioned in the guide.\",\n",
      "        \"Learn about databases and version control systems like Git.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Practice with Projects\",\n",
      "      \"sub_tasks\": [\n",
      "        \"Build projects that integrate frontend and backend skills, as suggested by the guide.\",\n",
      "        \"Participate in coding challenges or contribute to open-source projects to gain experience.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Success\n",
      "Tool Calling Required:  False\n",
      "Decision: Ending Chat (Final Answer)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Example Usage ---\n",
    "import uuid # For generating tool_call_id\n",
    "from datetime import datetime\n",
    "\n",
    "# Test 1: Simple query, no tool needed\n",
    "print(\"--- Test 1: Direct Answer ---\")\n",
    "inputs = {\"input\": \"I want to learn full stack development\", \"chat_history\": []}\n",
    "# for s in app.stream(inputs):\n",
    "#     print(s)\n",
    "# print(\"\\n\")\n",
    "\n",
    "result = app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a39213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Understand Full Stack Development',\n",
       "  'sub_tasks': ['Read the definition of Full Stack Development from the guide provided by the tool output.',\n",
       "   'Understand the components of a full stack, including frontend and backend.']},\n",
       " {'title': 'Frontend Skills',\n",
       "  'sub_tasks': [\"Learn HTML, CSS, and JavaScript as per the guide's recommendations.\",\n",
       "   'Explore popular front-end frameworks like React or Angular.']},\n",
       " {'title': 'Backend Skills',\n",
       "  'sub_tasks': ['Study backend languages such as Node.js, Python, or Ruby as mentioned in the guide.',\n",
       "   'Learn about databases and version control systems like Git.']},\n",
       " {'title': 'Practice with Projects',\n",
       "  'sub_tasks': ['Build projects that integrate frontend and backend skills, as suggested by the guide.',\n",
       "   'Participate in coding challenges or contribute to open-source projects to gain experience.']}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['final_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2360ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
